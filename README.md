# СОРТИРОВКА ВЫБОРОМ (Selection Sort)

## Определение:
Алгоритм, который на каждом шаге ищет минимальный элемент в неотсортированной части массива и помещает его в начало этой части.

## Анализ работы алгоритма (с пояснением синтаксиса C++ кода):
 • for (int i = 0; i < n; ++i) — внешний цикл перебирает все позиции массива.
 
 • int min_index = i — предполагаем, что текущий элемент минимальный.
 
 • for (int j = i + 1; j < n; ++j) — внутренний цикл ищет настоящий минимальный элемент в оставшейся части массива.
 
 • if (arr[j] < arr[min_index]) min_index = j; — если найден элемент меньше текущего минимума, обновляем индекс минимального элемента.
 
 • std::swap(arr[i], arr[min_index]); — обмен местами текущего элемента с найденным минимумом.
 
 • После выполнения всех итераций внешний цикл завершает сортировку всего массива.
 
 • В main() создается тестовый массив, выводится исходный массив, вызывается функция сортировки и выводится отсортированный массив.

## Временная сложность:
 • Лучший случай: O(n²)
 
 • Средний случай: O(n²)
 
 • Худший случай: O(n²)

## Почему O(n²):
Два вложенных цикла: внешний выполняется n раз, внутренний — почти n раз на каждой итерации. Для каждого элемента алгоритм просматривает всю оставшуюся часть массива, чтобы найти минимум. Общее количество операций пропорционально n × n, то есть квадратично зависит от размера массива.

## Пример работы:
Исходный массив: [64, 25, 12, 22, 11]

Отсортированный массив: [11, 12, 22, 25, 64]




# СОРТИРОВКА ОБМЕНОМ (пузырьком) (Bubble Sort)

## Определение:
Алгоритм, который многократно проходит по массиву, сравнивает соседние элементы и меняет их местами, если они находятся в неправильном порядке. На каждом проходе «всплывает» самый большой элемент к концу массива.

## Анализ работы алгоритма (с пояснением синтаксиса Python кода):
 • for i in range(n - 1): — внешний цикл отвечает за количество проходов по массиву.
 
 • for j in range(n - i - 1): — внутренний цикл сравнивает соседние элементы; диапазон уменьшается, так как последние элементы уже на своих местах.
 
 • if arr[j] > arr[j + 1]: arr[j], arr[j + 1] = arr[j + 1], arr[j] — если элементы в неправильном порядке, меняем их местами.
 
 • print_array(arr) — функция для вывода массива на экран.
 
 • В main создается тестовый массив, выводится исходный массив, вызывается функция сортировки и выводится отсортированный массив.

## Временная сложность:
 • Лучший случай: O(n) — если массив уже отсортирован (при наличии оптимизации с флагом swapped).
 
 • Средний случай: O(n²)
 
 • Худший случай: O(n²)

## Почему такая сложность:
Два вложенных цикла: внешний выполняется n-1 раз, внутренний почти n раз на каждой итерации. Для каждого элемента происходит сравнение с соседним элементом, что приводит к квадратичной зависимости от размера массива.

## Пример работы:
Исходный массив: [64, 34, 25, 12, 22, 11, 90]

Отсортированный массив: [11, 12, 22, 25, 34, 64, 90]


# СОРТИРОВКА ВСТАВКАМИ (Insertion Sort)

## Определение:
Алгоритм, который проходит по массиву, начиная со второго элемента, и вставляет каждый элемент в правильную позицию относительно уже отсортированной части массива.

## Анализ работы алгоритма (с пояснением синтаксиса Python кода):
 • for i in range(1, len(array)): — внешний цикл перебирает элементы массива начиная со второго (array[1]), так как первый элемент считается уже отсортированным.
 
 • key = array[i] — сохраняем текущий элемент, который нужно вставить в отсортированную часть массива.
 
 • j = i - 1 — индекс элемента, с которым будет происходить сравнение.
 
 • while j >= 0 and array[j] > key: — пока текущий элемент больше key, сдвигаем его на одну позицию вправо.
 
 • array[j + 1] = key — вставляем key на правильное место в отсортированной части.
 
 • print_array(array) — функция для вывода массива.

## Временная сложность:
 • Лучший случай: O(n) — если массив уже отсортирован (не выполняются сдвиги).
 
 • Средний случай: O(n²)
 
 • Худший случай: O(n²) — если массив отсортирован в обратном порядке.

## Почему такая сложность:
В худшем случае, для каждого элемента выполняется сдвиг всех предыдущих элементов на одну позицию, что приводит к суммарному количеству операций, пропорциональному 1 + 2 + … + (n-1) = n(n-1)/2 ~ O(n²).

## Пример работы:
Исходный массив: [12, 11, 13, 5, 6]

Отсортированный массив: [5, 6, 11, 12, 13]


# СОРТИРОВКА СЛИЯНИЕМ (Merge Sort)

## Определение:
Алгоритм, который делит массив на две части, рекурсивно сортирует каждую часть, а затем сливает их в один отсортированный массив. Это пример алгоритма “разделяй и властвуй” (divide and conquer).

## Анализ работы алгоритма (с пояснением синтаксиса C++ кода):
 • vector<int> merge(const vector<int>& left, const vector<int>& right) — функция для слияния двух отсортированных массивов:
 
 • while (i < left.size() && j < right.size()) — сравниваем элементы из левой и правой частей; меньший элемент добавляется в результат.
 
 • result.insert(result.end(), left.begin() + i, left.end()) и аналогично для правой части — добавляем оставшиеся элементы.
 
 • vector<int> merge_sort(const vector<int>& arr) — рекурсивная функция сортировки:
 
 • if (arr.size() <= 1) return arr; — базовый случай: массив длиной 0 или 1 уже отсортирован.
 
 • Делим массив на left и right по середине.
 
 • Рекурсивно вызываем merge_sort(left) и merge_sort(right).
 
 • return merge(left, right); — сливаем отсортированные части.
 
 • В main() создается массив, выводится исходный массив, вызывается функция сортировки, выводится отсортированный массив.

## Временная сложность:
 • Лучший случай: O(n log n)
 
 • Средний случай: O(n log n)
 
 • Худший случай: O(n log n)

## Почему O(n log n):
 • Массив рекурсивно делится пополам на каждом уровне (log n уровней рекурсии).
 
 • На каждом уровне выполняется слияние всех элементов, что требует O(n) операций.
 
 • В итоге общее количество операций равно O(n × log n).

## Пример работы:
Исходный массив: [38, 27, 43, 3, 9, 82, 10]

Отсортированный массив: [3, 9, 10, 27, 38, 43, 82]


# СОРТИРОВКА ШЕЛЛА (Shell Sort)

## Определение:
Алгоритм, который улучшает сортировку вставками, сравнивая элементы на определенном «шаге» (gap), постепенно уменьшая шаг до 1. Это позволяет быстрее перемещать элементы на большие расстояния и уменьшает общее количество сравнений.

## Анализ работы алгоритма (с пояснением синтаксиса Java кода):
 • for (int gap = n / 2; gap > 0; gap /= 2) — внешний цикл задает промежуток между сравниваемыми элементами; на каждом шаге gap уменьшается вдвое.
 
 • for (int i = gap; i < n; i++) — цикл перебирает элементы массива, начиная с позиции gap.
 
 • int temp = arr[i]; — сохраняем текущий элемент для вставки.
 
 • for (j = i; j >= gap && arr[j - gap] > temp; j -= gap) arr[j] = arr[j - gap]; — сдвигаем элементы, которые больше temp, вправо на шаг gap.
 
 • arr[j] = temp; — вставляем элемент на правильное место.
 
 • printArray(arr) — вывод массива на экран.
 
 • В main() создается массив, выводится исходный массив, вызывается сортировка и выводится отсортированный массив.

## Временная сложность:
 • Лучший случай: O(n log n) — при хорошо подобранных промежутках gap.
 
 • Средний случай: ≈ O(n^1.25)
 
 • Худший случай: O(n²)
 

## Почему такая сложность:
 • Алгоритм уменьшает количество сдвигов по сравнению с обычной сортировкой вставками, начиная с больших шагов gap.
 
 • На каждом шаге элементы частично упорядочиваются, а затем при gap = 1 сортировка превращается в обычную вставку, но уже с меньшим количеством операций.
 
 • Сложность сильно зависит от выбора последовательности шагов (gap sequence).

## Пример работы:
Исходный массив: [12, 34, 54, 2, 3]

Отсортированный массив: [2, 3, 12, 34, 54]


# БЫСТРАЯ СОРТИРОВКА (Quick Sort)

## Определение:
Алгоритм “разделяй и властвуй” (divide and conquer), который выбирает опорный элемент (pivot), делит массив на элементы меньше и больше pivot и рекурсивно сортирует эти части.

## Анализ работы алгоритма (с пояснением синтаксиса Python кода):
 • quick_sort(array, low, high) — основной рекурсивный метод сортировки.
 
 • if low < high: — проверка, есть ли элементы для сортировки.
 
 • pi = partition(array, low, high) — находим индекс опорного элемента, который окажется на своём месте.
 
 • quick_sort(array, low, pi - 1) и quick_sort(array, pi + 1, high) — рекурсивно сортируем левую и правую части массива.
 
 • partition(array, low, high) — метод разбиения:
 
 • pivot = array[high] — выбираем последний элемент в качестве опорного.
 
 • i = low - 1 — индекс для элементов меньше pivot.
 
 • for j in range(low, high): — перебираем все элементы, кроме pivot.
 
 • if array[j] <= pivot: i += 1; array[i], array[j] = array[j], array[i] — если элемент меньше или равен pivot, меняем его с элементом на позиции i.
 
 • array[i + 1], array[high] = array[high], array[i + 1] — ставим pivot на правильное место.
 
 • print_array(array) — функция для вывода массива.

## Временная сложность:
 • Лучший случай: O(n log n) — когда pivot делит массив примерно пополам.
 
 • Средний случай: O(n log n)
 
 • Худший случай: O(n²) — когда pivot выбирается неудачно (например, всегда наименьший или наибольший элемент).

## Почему такая сложность:
 • На каждом уровне рекурсии массив делится на две части; если деление сбалансировано, глубина рекурсии ~ log n.
 
 • На каждом уровне выполняются сравнения всех n элементов для разбиения.
 
 • В худшем случае глубина рекурсии становится n, что даёт O(n²) операций.

## Пример работы:
Исходный массив: [10, 7, 8, 9, 1, 5]

Отсортированный массив: [1, 5, 7, 8, 9, 10]


# ПИРАМИДАЛЬНАЯ СОРТИРОВКА (Heap Sort)

## Определение:
Алгоритм сортировки, который строит бинарную кучу (max-heap) из массива, затем последовательно извлекает максимальный элемент и помещает его в конец массива, повторяя процесс до полной сортировки.

## Анализ работы алгоритма (с пояснением синтаксиса C++ кода):
 • void heapify(std::vector<int>& arr, int n, int i) — функция, которая обеспечивает свойство max-heap:
 
 • largest = i — предполагаем, что корень является наибольшим элементом.
 
 • left = 2*i + 1, right = 2*i + 2 — индексы левого и правого дочерних элементов.
 
 • if (left < n && arr[left] > arr[largest]) largest = left; — проверяем левый дочерний элемент.
 
 • if (right < n && arr[right] > arr[largest]) largest = right; — проверяем правый дочерний элемент.
 
 • if (largest != i) { std::swap(arr[i], arr[largest]); heapify(arr, n, largest); } — если корень не наибольший, меняем местами и рекурсивно применяем heapify.
 • void heap_sort(std::vector<int>& arr) — основная функция сортировки:
 
 • for (int i = n/2 - 1; i >= 0; i--) heapify(arr, n, i); — строим max-heap из массива.
 
 • for (int i = n-1; i > 0; i--) { std::swap(arr[0], arr[i]); heapify(arr, i, 0); } — последовательно извлекаем максимальные элементы и восстанавливаем кучу.
 
 • В main() создается массив, выводится исходный массив, вызывается сортировка и выводится отсортированный массив.

## Временная сложность:
 • Лучший случай: O(n log n)
 
 • Средний случай: O(n log n)
 
 • Худший случай: O(n log n)

## Почему O(n log n):
 • Построение кучи выполняется за O(n).
 
 • Извлечение каждого из n элементов требует O(log n) операций для поддержания кучи.
 
 • В сумме общее количество операций равно O(n) + O(n log n) ~ O(n log n).

## Пример работы:
Исходный массив: [12, 11, 13, 5, 6, 7]

Отсортированный массив: [5, 6, 7, 11, 12, 13]


# ПОСЛЕДОВАТЕЛЬНЫЙ ПОИСК (Linear Search)

## Определение:
Алгоритм поиска, который проверяет каждый элемент массива по порядку до тех пор, пока не найдет искомый элемент или не достигнет конца массива.

## Анализ работы алгоритма (с пояснением синтаксиса Python кода):
 • for i in range(len(arr)): — внешний цикл перебирает все элементы массива.
 
 • if arr[i] == target: return i — если текущий элемент совпадает с искомым, возвращаем его индекс.
 
 • return -1 — если элемент не найден после проверки всех элементов, возвращаем -1.
 
 • В main создается массив array, задается искомое значение target, вызывается функция linear_search, выводится результат поиска.

## Временная сложность:
 • Лучший случай: O(1) — если искомый элемент находится в начале массива.
 
 • Средний случай: O(n) — в среднем придётся проверить половину элементов массива.
 
 • Худший случай: O(n) — если элемент находится в конце массива или отсутствует.


## Почему такая сложность:
 • Алгоритм проверяет элементы массива последовательно, по одному.
 
 • Количество проверок пропорционально числу элементов n, что даёт линейную зависимость.
 
 • Эффективен для небольших массивов или когда элемент с большой вероятностью находится в начале.

## Пример работы:
Массив: [3, 5, 2, 7, 9, 1, 4]

Искомый элемент: 7

Результат: Элемент найден на позиции: 3


# БИНАРНЫЙ ПОИСК (Binary Search)

## Определение:
Алгоритм поиска, который работает только на отсортированных массивах. На каждом шаге проверяется средний элемент, после чего поиск продолжается в левой или правой половине массива в зависимости от сравнения с искомым элементом.

## Анализ работы алгоритма (с пояснением синтаксиса Python кода):
 • left = 0 и right = len(array) - 1 — задаем границы поиска.
 
 • while left <= right: — пока границы не пересеклись, продолжаем поиск.
 
 • mid = left + (right - left) // 2 — находим индекс среднего элемента.
 
 • if array[mid] == target: return mid — если средний элемент равен искомому, возвращаем индекс.
 
 • if array[mid] > target: right = mid - 1 — если средний элемент больше искомого, сдвигаем правую границу влево.
 
 • else: left = mid + 1 — если средний элемент меньше искомого, сдвигаем левую границу вправо.
 
 • return -1 — если элемент не найден, возвращаем -1.

## Временная сложность:
 • Лучший случай: O(1) — если искомый элемент находится точно в середине массива на первом шаге.
 
 • Средний случай: O(log n) — каждый шаг сокращает размер рассматриваемого массива вдвое.
 
 • Худший случай: O(log n) — если элемент находится в крайней половине массива или отсутствует, алгоритм всё равно делает примерно log₂(n) сравнений.

## Почему O(log n):
 • Алгоритм работает по принципу “дели и властвуй”: на каждом шаге исключается половина массива.
 
 • Для массива длины n максимальное количество делений, необходимых для поиска, равно log₂(n).
 
 • Логарифмическая сложность сохраняется независимо от расположения элемента в массиве.

## Пример работы:
Массив: [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]

Искомый элемент: 7

Результат: Элемент найден на позиции: 3


# ИНТЕРПОЛЯЦИОННЫЙ ПОИСК (Interpolation Search)

## Определение:
Алгоритм поиска для отсортированных массивов, который пытается предсказать позицию искомого элемента на основе линейной интерполяции, а не делит массив пополам, как бинарный поиск.

## Анализ работы алгоритма (с пояснением синтаксиса C++ кода):
 • int pos = lo + ((hi - lo) * (x - arr[lo])) / (arr[hi] - arr[lo]); — вычисляем предполагаемую позицию искомого элемента по формуле интерполяции.
 
 • if (arr[pos] == x) return pos; — если на предполагаемой позиции находится искомый элемент, возвращаем индекс.
 
 • if (arr[pos] < x) return interpolationSearch(arr, pos + 1, hi, x); — если элемент меньше искомого, ищем в правой части массива.
 
 • if (arr[pos] > x) return interpolationSearch(arr, lo, pos - 1, x); — если элемент больше искомого, ищем в левой части массива.
 
 • Базовый случай: if (lo > hi  x < arr[lo]  x > arr[hi]) return -1; — если элемент не найден, возвращаем -1.
 
 • В main() создается массив, задается искомый элемент x, вызывается функция поиска и выводится результат.

## Временная сложность:
 • Лучший случай: O(1) — если искомый элемент находится на предполагаемой позиции сразу.
 
 • Средний случай: O(log log n) — при равномерном распределении элементов, так как алгоритм сразу прыгает ближе к нужной позиции.
 
 • Худший случай: O(n) — при неравномерном распределении элементов, когда каждый шаг алгоритма продвигается очень медленно, почти как последовательный поиск.

## Почему такая сложность:
 • Алгоритм использует линейную интерполяцию, чтобы предсказать индекс элемента, а не просто делит массив пополам (как бинарный поиск).
 
 • При равномерном распределении диапазон поиска сокращается экспоненциально быстрее, чем у бинарного поиска, что даёт O(log log n).
 
 • При неравномерном распределении интерполяция может быть неточной, и поиск может деградировать до последовательного, что даёт O(n).

## Пример работы:
Массив: [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]

Искомый элемент: 70

Результат: Элемент найден на позиции: 6


# ПОИСК ФИБОНАЧЧИ (Fibonacci Search)

## Определение:
Алгоритм поиска в отсортированном массиве, который использует последовательность Фибоначчи для определения смещений и деления массива на участки. Подобен бинарному поиску, но вместо деления пополам используется последовательность Фибоначчи.

## Анализ работы алгоритма (с пояснением синтаксиса Python кода):
 • while fib_m < n: — находим наименьшее число Фибоначчи fib_m, большее или равное длине массива.
 
 • offset = -1 — смещение, которое отслеживает уже проверенные элементы.
 
 • while fib_m > 1: — основной цикл поиска:
 
 • i = min(offset + fib_m2, n - 1) — вычисляем индекс для сравнения с x.
 
 • if arr[i] < x: — если элемент меньше искомого, сдвигаем смещение вправо и обновляем числа Фибоначчи.
 
 • elif arr[i] > x: — если элемент больше, ищем в левом подмассиве.
 
 • else: return i — элемент найден, возвращаем индекс.
 
 • Проверка последнего элемента: if fib_m1 and offset + 1 < n and arr[offset + 1] == x:
 
 • Возврат -1, если элемент не найден.
 
 • В main создается массив arr, задается искомый элемент x, вызывается функция fibonacci_search, выводится результат.

## Временная сложность:
 • Лучший случай: O(1) — если элемент находится на предполагаемой позиции сразу.
 
 • Средний случай: O(log n) — каждый шаг уменьшает диапазон поиска примерно на число Фибоначчи, что даёт логарифмическую зависимость.
 
 • Худший случай: O(log n) — аналогично бинарному поиску, так как количество сравнений ограничено числами Фибоначчи.

## Почему O(log n):
 • Диапазон поиска уменьшается по числам Фибоначчи (F[m-1], F[m-2]), что примерно соответствует делению массива на части по принципу золотого сечения.
 
 • Максимальное количество шагов поиска пропорционально количеству чисел Фибоначчи, покрывающих массив, что равно O(log n).
 
## Пример работы:
Массив: [10, 22, 35, 40, 45, 50, 80, 82, 85, 90, 100]

Искомый элемент: 85

Результат: Элемент найден на позиции: 8



